# -*- coding: utf-8 -*-
"""text_alignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/172d98qoD0IYtrnKPNkXd8BseMjswIYGW
"""

!pip install biopython

"""**below code has included all the steps but leaving two: start and end wale**its working for 1 sentence"""

import re
from Bio import pairwise2

# Define constants as per your requirement
MATCH_REWARD = 1
MISMATCH_PENALTY = -1
GAP_PENALTY = -2
GAP_EXT_PENALTY = -0.5
SPACE_MISMATCH_PENALTY = -2
GAP_CHAR = '@'
ONE_ALIGNMENT_ONLY = True

def _join_char_list(alignment_tuple):
    """Post-process alignment results for unicode support"""
    gt_char_list, noise_char_list, score, start, end = alignment_tuple
    return "".join(gt_char_list), "".join(noise_char_list), score, start, end

def _align_seg(
    gt,
    noise,
    match_reward=MATCH_REWARD,
    mismatch_pen=MISMATCH_PENALTY,
    gap_pen=GAP_PENALTY,
    gap_ext_pen=GAP_EXT_PENALTY,
    space_mismatch_penalty=SPACE_MISMATCH_PENALTY,
    gap_char=GAP_CHAR,
    one_alignment_only=ONE_ALIGNMENT_ONLY,
):
    """Wrapper function for Bio.pairwise2.align.globalms(), which
    calls the sequence alignment algorithm (Needleman-Wunsch)"""

    def match_reward_fn(x, y):
        if x == y:
            return match_reward
        elif x == " " or y == " ":
            # mismatch of a character with a space gets a stronger penalty
            return mismatch_pen - space_mismatch_penalty
        else:
            return mismatch_pen

    # Perform sequence alignment using pairwise2
    alignments = pairwise2.align.globalcs(
        list(gt),
        list(noise),
        match_reward_fn,
        gap_pen,
        gap_ext_pen,
        gap_char=[gap_char],
        one_alignment_only=one_alignment_only,
    )

    # Post-process alignments for Unicode support
    processed_alignments = list(map(_join_char_list, alignments))

    return processed_alignments

def _select_alignment_candidates(alignments, target_num_gt_tokens):
    """Select the first alignment candidate with the desired number of ground truth tokens"""
    for alignment in alignments:
        aligned_gt = alignment[0]
        aligned_noise = alignment[1]
        num_aligned_gt_tokens = len(tokenize(aligned_gt))

        if num_aligned_gt_tokens == target_num_gt_tokens:
            if len(aligned_gt) != len(aligned_noise):
                raise ValueError(
                    f"Aligned strings are not equal in length: \naligned_gt: '{aligned_gt}'\naligned_noise '{aligned_noise}'\n"
                )
            return alignment

    raise ValueError(
        f"No alignment candidates with {target_num_gt_tokens} tokens. Total candidates: {len(alignments)}"
    )

def tokenize(s):
    """Example tokenize function - split by whitespace"""
    return s.split()

def align(gt, noise, gap_char=GAP_CHAR):
    """Align two text segments via sequence alignment algorithm

    **NOTE**: this algorithm is O(N^2) and is NOT efficient for longer text.
    Please refer to `genalog.text.anchor` for faster alignment on longer strings.

    Arguments:
        gt (str) : ground true text (should not contain GAP_CHAR)
        noise (str) : str with ocr noise (should not contain GAP_CHAR)
        gap_char (char, optional) : gap char used in alignment algorithm (default: GAP_CHAR)

    Returns:
        tuple(str, str) : a tuple of aligned ground truth and noise

    Invariants:
        The returned aligned strings will satisfy the following invariants:

        1. ``len(aligned_gt) == len(aligned_noise)``
        2. ``number of tokens in gt == number of tokens in aligned_gt``

    Example:
    ::

                    gt: "arabic"
                    noise: "abrabic"
                    aligned_gt: "arabic"
                    aligned_noise: "abrabic"

    """
    if not gt and not noise:  # Both inputs are empty string
        return "", ""
    elif not gt:  # Either is empty
        return gap_char * len(noise), noise
    elif not noise:
        return gt, gap_char * len(gt)
    else:
        num_gt_tokens = len(tokenize(gt))
        alignments = _align_seg(gt, noise, gap_char=gap_char)
        try:
            aligned_gt, aligned_noise, _, _, _ = _select_alignment_candidates(
                alignments, num_gt_tokens
            )
        except ValueError as e:
            raise ValueError(
                f"Error with input strings '{gt}' and '{noise}': \n{str(e)}"
            )
        return aligned_gt, aligned_noise

def _is_valid_token(token, gap_char=GAP_CHAR):
    """Returns true if token is valid (i.e. composed of non-gap characters)
        Invalid tokens are
            1. multiple occurrences of the GAP_CHAR (e.g. '@@@')
            2. empty string ("")
            3. string with spaces ("  ")

        **Important: this method expects one token and not multiple space-separated tokens

    Arguments:
        token (str) : input string token
        gap_char (char, optional) : gap char used in alignment algorithm. Defaults to GAP_CHAR.

    Returns:
        bool : True if is a valid token, false otherwise
    """
    # Matches multiples of 'gap_char' that are padded with whitespace characters on either end
    INVALID_TOKEN_REGEX = (
        rf"^\s*{re.escape(gap_char)}*\s*$"  # Escape special regex chars
    )
    return not re.match(INVALID_TOKEN_REGEX, token)


def parse_alignment(aligned_gt, aligned_noise, gap_char=GAP_CHAR):
    r"""Parse alignment to pair ground truth tokens with noise tokens
    ::

                    Case 1:         Case 2:         Case 3:         Case 4:         Case 5:
                    one-to-many     many-to-one     many-to-many    missing
                    tokens  one-to-one
              gt    "New York"      "New York"      "New York"      "New York"      "New York"
                      |   |           |   |           |   |           |   |           |   |
       aligned_gt   "New Yo@rk"     "New York"      "N@ew York"     "New York"      "New York"
                      |   /\           \/             /\/             |   |           |   |
     aligned_noise  "New Yo rk"     "New@York"      "N ew@York"     "New @@@@"      "New York"
                      |   | |           |            |    |           |               |   |
            noise   "New Yo rk"     "NewYork"       "N ewYork"      "New"           "New York"

    Arguments:
        aligned_gt (str) : ground truth string aligned with the noise string
        aligned_noise (str) : noise string aligned with the ground truth
        gap_char (char, optional) : gap char used in alignment algorithm. Defaults to GAP_CHAR.

    Returns:
        tuple : ``(gt_to_noise_mapping, noise_to_gt_mapping)`` of two 2D int arrays:

    where each array defines the mapping between aligned gt tokens
    to noise tokens and vice versa.

    Example:
        Given input
        ::

                    aligned_gt: "N@ew York @is big"
                                /\\   |    |   |
                aligned_noise: "N ew@York kis big."

        The returned output will be:
        ::

                ([[0,1],[1],[2],[3]], [[0],[0,1],[2],[3]])
    """
    if len(aligned_gt) != len(aligned_noise):
        raise ValueError("Aligned strings are not equal in length")

    total_gt_tokens = len(tokenize(aligned_gt))
    total_noise_tokens = len(tokenize(aligned_noise))

    # Initialization
    aligned_gt += " "  # add whitespace padding to prevent ptr overflow
    aligned_noise += " "  # add whitespace padding to prevent ptr overflow
    tk_index_gt = tk_index_noise = 0
    tk_start_gt, tk_end_gt = _find_next_token(aligned_gt, 0)
    tk_start_noise, tk_end_noise = _find_next_token(aligned_noise, 0)
    gt_to_noise_mapping = [[] for _ in range(total_gt_tokens)]
    noise_to_gt_mapping = [[] for _ in range(total_noise_tokens)]

    while tk_index_gt < total_gt_tokens or tk_index_noise < total_noise_tokens:
        # If both tokens are aligned (one-to-one case)
        if tk_end_gt == tk_end_noise:
            # if both gt_token and noise_token are valid (missing token case)
            if _is_valid_token(aligned_gt[tk_start_gt:tk_end_gt], gap_char=gap_char) and _is_valid_token(
                aligned_noise[tk_start_noise:tk_end_noise], gap_char=gap_char
            ):
                # register the index of these tokens in the gt_to_noise_mapping
                gt_to_noise_mapping[tk_index_gt].append(tk_index_noise)
                # register the index of these tokens in the noise_to_gt_mapping
                noise_to_gt_mapping[tk_index_noise].append(tk_index_gt)
            # find the start and end of the next gt_token and noise_token
            tk_start_gt, tk_end_gt = _find_next_token(aligned_gt, tk_end_gt)
            tk_start_noise, tk_end_noise = _find_next_token(aligned_noise, tk_end_noise)
            tk_index_gt += 1
            tk_index_noise += 1
        # If gt_token is shorter than noise_token (many-to-one case)
        elif tk_end_gt < tk_end_noise:
            while tk_end_gt < tk_end_noise:
                # if both gt_token and noise_token are valid (missing token case)
                if _is_valid_token(aligned_gt[tk_start_gt:tk_end_gt], gap_char=gap_char) and _is_valid_token(
                    aligned_noise[tk_start_noise:tk_end_noise], gap_char=gap_char
                ):
                    # register the index of these tokens in the gt_to_noise_mapping
                    gt_to_noise_mapping[tk_index_gt].append(tk_index_noise)
                    # register the index of these tokens in the noise_to_gt_mapping
                    noise_to_gt_mapping[tk_index_noise].append(tk_index_gt)
                # Find the next gt_token
                tk_start_gt, tk_end_gt = _find_next_token(aligned_gt, tk_end_gt)
                # Increment index
                tk_index_gt += 1
        # If gt_token is longer than noise_token (one-to-many case)
        else:
            while tk_end_gt > tk_end_noise:
                # if both gt_token and noise_token are valid (missing token case)
                if _is_valid_token(aligned_gt[tk_start_gt:tk_end_gt], gap_char=gap_char) and _is_valid_token(
                    aligned_noise[tk_start_noise:tk_end_noise], gap_char=gap_char
                ):
                    # register the index of these token in the gt_to_noise_mapping
                    gt_to_noise_mapping[tk_index_gt].append(tk_index_noise)
                    # register the index of these token in the noise_to_gt_mapping
                    noise_to_gt_mapping[tk_index_noise].append(tk_index_gt)
                # Find the next gt_token
                tk_start_noise, tk_end_noise = _find_next_token(aligned_noise, tk_end_noise)
                # Increment index
                tk_index_noise += 1

    return gt_to_noise_mapping, noise_to_gt_mapping


def _find_next_token(s, start_index):

    end_index = start_index
    # Move end_index until a whitespace is encountered
    while end_index < len(s) and not s[end_index].isspace():
        end_index += 1
    return start_index, end_index

def _format_alignment(align1, align2):

    formatted_str = pairwise2.format_alignment(
        align1, align2, 0, 0, len(align1), full_sequences=True
    )
    # Remove the "Score=0" from the str
    formatted_str_no_score = formatted_str.replace("\n  Score=0", "")
    return formatted_str_no_score

def generate_labels(aligned_gt, aligned_noise):
    # Tokenize aligned_gt and aligned_noise into words or tokens
    tokens_gt = tokenize(aligned_gt)
    tokens_noise = tokenize(aligned_noise)

    # Initialize an empty list to store labels
    labels = []

    # Iterate through tokens_gt and compare with corresponding tokens_noise
    for token_gt, token_noise in zip(tokens_gt, tokens_noise):
        # Assign label based on whether the tokens match
        label = 0 if token_gt == token_noise else 1
        labels.append(label)

    return labels


# Example usage
gt = "कछ ज़िले जे भुॼ शहर मां शायअ थींदड़ रोज़ाना अख़िबार"
noise = "कछ ज़िले जे भुॼ शहर मां शायअ थींदड़ रोज़ाज़नो अख़िार"
aligned_gt, aligned_noise = align(gt, noise)
print("Aligned GT: ", aligned_gt)
print("Aligned Noise: ", aligned_noise)
print(_format_alignment(aligned_gt, aligned_noise))

labels = generate_labels(aligned_gt, aligned_noise)
print(labels)